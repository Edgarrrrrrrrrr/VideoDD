[32m2025-03-15 23:09:29.190[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m101[0m - [1mHyper-parameters:
{'_wandb': {}, 'dataset': 'HMDB51', 'method': 'CF', 'model': 'ConvNet3D', 'data_path': '/root/autodl-tmp/Data', 'Iteration': 3000, 'eval_it': 500, 'eval_mode': 'SS', 'batch_syn': 51, 'ipc': 1, 'frames': 16, 'lr_teacher': 0.001, 'init': 'real', 'lr_video': 20.0, 'sampling_net': 0, 'lr_sampling_net': 0.01, 'alpha_for_loss': 0.5, 'beta_for_loss': 0.5, 'iter_calib': 0, 'calib_weight': 1, 'num_freqs': 1024, 'outer_loop': None, 'inner_loop': None, 'num_eval': 5, 'epoch_eval_train': 500, 'lr_net': 0.01, 'lr_lr': 1e-05, 'train_lr': False, 'batch_real': 64, 'batch_train': 256, 'expert_epochs': 3, 'syn_steps': 64, 'max_start_epoch': 25, 'dis_metric': 'ours', 'buffer_path': None, 'num_workers': 4, 'preload': True, 'save_path': './logged_files', 'device': 'cuda', 'distributed': False}[0m
[32m2025-03-15 23:09:29.191[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m102[0m - [1mEvaluation model pool: ['ConvNet3D'][0m
[32m2025-03-15 23:09:29.191[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m106[0m - [1mBUILDING DATASET[0m
5236it [00:00, 709300.94it/s]
[32m2025-03-15 23:09:29.389[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m145[0m - [1minitialize synthetic data from random real video[0m
torch.Size([51, 3, 16, 112, 112])
[32m2025-03-15 23:09:29.456[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m170[0m - [1mtraining begins[0m
[32m2025-03-15 23:09:29.456[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m175[0m - [1mËí∏È¶èÊï∞ÊçÆÈõÜÁöÑÂ∞∫ÂØ∏Ôºötorch.Size([51, 3, 16, 112, 112])[0m
[32m2025-03-15 23:09:29.456[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m176[0m - [1mËí∏È¶èÊï∞ÊçÆÈõÜÊ†áÁ≠æÁöÑÂ∞∫ÂØ∏Ôºötorch.Size([51])[0m
[32m2025-03-15 23:09:31.453[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m224[0m - [1mUse CF method[0m
  0%|                                                                                                                                                  | 0/3001 [00:00<?, ?it/s][32m2025-03-15 23:09:31.454[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m227[0m - [1mÂΩìÂâçÂ≠¶‰π†Áéá: 20.0[0m
[32m2025-03-15 23:09:31.454[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m262[0m - [1mËøôÊ¨°ËÆ≠ÁªÉËΩÆÊï∞ÊòØ:0[0m
match_loss_totalÊòØ 1460.027621269226
calib_loss_totalÊòØ 0
current_lossÊòØ 28.627992573906393
  0%|                                                                                                                                       | 1/3001 [00:18<15:06:00, 18.12s/it][32m2025-03-15 23:09:49.574[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m227[0m - [1mÂΩìÂâçÂ≠¶‰π†Áéá: 20.0[0m
[32m2025-03-15 23:09:49.575[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m236[0m - [1mEvaluation model_train = ConvNet3D, model_eval = ConvNet3D, iteration = 1[0m
start ep
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 400/501 [03:03<00:46,  2.18it/s]
  0%|                                                                                                                                     | 1/3001 [03:21<167:45:23, 201.31s/it]
[2025-03-15 23:10:38] Evaluate_00: Ep 100 time = 48s loss = 0.155465 train acc = 94.12, test acc = 5.03
[2025-03-15 23:11:25] Evaluate_00: Ep 200 time = 96s loss = 0.098672 train acc = 98.04, test acc = 4.42
lr = 0.001000
[2025-03-15 23:12:11] Evaluate_00: Ep 300 time = 142s loss = 0.002448 train acc = 100.00, test acc = 5.88
Traceback (most recent call last):
  File "/root/autodl-tmp/VideoDD/TzxDemo.py", line 492, in <module>
    main(args)
  File "/root/autodl-tmp/VideoDD/TzxDemo.py", line 242, in main
    _, acc_train, acc_test, acc_per_cls = evaluate_synset(it_eval, net_eval, image_syn_eval, label_syn_eval, testloader, args, mode='none',test_freq=100)
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/VideoDD/utils.py", line 1074, in evaluate_synset
    loss_test, acc_test, acc_per= epoch('test', testloader, net, optimizer, criterion, args)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/VideoDD/utils.py", line 946, in epoch
    for i_batch, datum in enumerate(dataloader):
  File "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/root/autodl-tmp/VideoDD/distill_utils/dataset.py", line 340, in __getitem__
    X = self.read_images(
        ^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/VideoDD/distill_utils/dataset.py", line 316, in read_images
    image = use_transform(image)
            ^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
           ^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torchvision/transforms/functional.py", line 168, in to_tensor
    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/PIL/Image.py", line 696, in __array_interface__
    new["data"] = self.tobytes()
                  ^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/PIL/Image.py", line 768, in tobytes
    bytes_consumed, errcode, data = e.encode(bufsize)
                                    ^^^^^^^^^^^^^^^^^
KeyboardInterrupt
